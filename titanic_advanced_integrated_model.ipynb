{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "2dbd643d",
            "metadata": {},
            "source": [
                "# íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡ - [THE LAST CHANCE] 0.81 ëŒíŒŒ ìµœì¢… ë³‘ê¸°\n",
                "\n",
                "ì´ ë…¸íŠ¸ë¶ì€ ë§ˆì§€ë§‰ ì—…ë¡œë“œ ê¸°íšŒë¥¼ ì„±ê³µì‹œí‚¤ê¸° ìœ„í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "### ğŸ› ï¸ ìµœì¢… ìˆ˜ê³µì˜ˆ íŠœë‹:\n",
                "1. **Corrected Fare Scaling**: ì¸ë‹¹ ìš”ê¸ˆì„ ë¨¼ì € êµ¬í•œ ë’¤ ë¡œê·¸ ë³€í™˜ì„ ì ìš©í•˜ì—¬ ê²½ì œì  ì§€ìœ„ ì •ë³´ë¥¼ ì™„ë²½íˆ ë³´ì •\n",
                "2. **Balanced Age Imputation**: ê³¼ì í•©ì„ ìœ ë°œí–ˆë˜ ì„¸ë¶„í™”ëœ ë‚˜ì´ ë³´ì •ì„ Titleê³¼ Pclass ê¸°ì¤€ìœ¼ë¡œ ë‹¨ìˆœí™”í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ í™•ë³´\n",
                "3. **Golden Weighting**: SVC, RF, XGB, ET ì¡°í•©ì—ì„œ ê²€ì¦ëœ í™©ê¸ˆ ë¹„ìœ¨ ê°€ì¤‘ì¹˜(2:2:1:1) ì ìš©\n",
                "4. **Group Survival Anchor**: ê°€ì¡±/í‹°ì¼“ ê·¸ë£¹ ìƒì¡´ ë¡œì§ì˜ ì„ê³„ì¹˜ ìµœì í™”"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0dcf97ee",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.base import BaseEstimator, TransformerMixin\n",
                "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier\n",
                "from sklearn.svm import SVC\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "train_df = pd.read_csv('c:/Users/alstj/github/DataScience/scikit-learn/data/titanic/train.csv')\n",
                "test_df = pd.read_csv('c:/Users/alstj/github/DataScience/scikit-learn/data/titanic/test.csv')\n",
                "all_data = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n",
                "\n",
                "# 1. Family Survival (WCG) - ê°€ì¥ ê²€ì¦ëœ ë¡œì§ ìœ ì§€\n",
                "all_data['Last_Name'] = all_data['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
                "all_data['Family_Survival'] = 0.5\n",
                "for grp, grp_df in all_data.groupby(['Last_Name', 'Fare']):\n",
                "    if (len(grp_df) > 1):\n",
                "        for ind, row in grp_df.iterrows():\n",
                "            smax = grp_df.drop(ind)['Survived'].max()\n",
                "            smin = grp_df.drop(ind)['Survived'].min()\n",
                "            if (smax == 1.0): all_data.loc[all_data['PassengerId'] == row['PassengerId'], 'Family_Survival'] = 1\n",
                "            elif (smin == 0.0): all_data.loc[all_data['PassengerId'] == row['PassengerId'], 'Family_Survival'] = 0\n",
                "for grp, grp_df in all_data.groupby('Ticket'):\n",
                "    if (len(grp_df) > 1):\n",
                "        for ind, row in grp_df.iterrows():\n",
                "            if (all_data.loc[all_data['PassengerId'] == row['PassengerId'], 'Family_Survival'].item() == 0.5):\n",
                "                smax = grp_df.drop(ind)['Survived'].max()\n",
                "                smin = grp_df.drop(ind)['Survived'].min()\n",
                "                if (smax == 1.0): all_data.loc[all_data['PassengerId'] == row['PassengerId'], 'Family_Survival'] = 1\n",
                "                elif (smin == 0.0): all_data.loc[all_data['PassengerId'] == row['PassengerId'], 'Family_Survival'] = 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7e42351b",
            "metadata": {},
            "outputs": [],
            "source": [
                "class TitanicTrueMasterEngineer(BaseEstimator, TransformerMixin):\n",
                "    def fit(self, X, y=None): return self\n",
                "    def transform(self, X):\n",
                "        X = X.copy()\n",
                "        X['Title'] = X['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
                "        X['Title'] = X['Title'].replace(['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'], 'Rare')\n",
                "        X['Title'] = X['Title'].replace(['Mlle', 'Ms'], 'Miss').replace('Mme', 'Mrs')\n",
                "        \n",
                "        # ë‚˜ì´ ë³´ì • (Title + Pclassë¡œ ë‹¨ìˆœí™”í•˜ì—¬ ë…¸ì´ì¦ˆ ì œê±°)\n",
                "        X['Age'] = X.groupby(['Title', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
                "        \n",
                "        # â˜…ìˆ˜ì •: ì¸ë‹¹ ìš”ê¸ˆ ê³„ì‚° í›„ ë¡œê·¸ ë³€í™˜ (ì˜¬ë°”ë¥¸ ìˆ˜í•™ì  ìˆœì„œ)\n",
                "        X['Ticket_Count'] = X.groupby('Ticket')['Ticket'].transform('count')\n",
                "        X['Fare_PP'] = X['Fare'].fillna(X['Fare'].median()) / X['Ticket_Count']\n",
                "        X['Fare_PP_Log'] = X['Fare_PP'].map(lambda i: np.log(i) if i > 0 else 0)\n",
                "        \n",
                "        X['FamilySize'] = X['SibSp'] + X['Parch'] + 1\n",
                "        X['Sex'] = X['Sex'].map({'male': 0, 'female': 1})\n",
                "        X['Sex_Pclass'] = X['Sex'].astype(str) + \"_\" + X['Pclass'].astype(str)\n",
                "        \n",
                "        return X.drop(['Name', 'Last_Name', 'Ticket', 'Cabin', 'PassengerId', 'SibSp', 'Parch', 'Fare', 'Fare_PP'], axis=1)\n",
                "\n",
                "num_features = ['Age', 'FamilySize', 'Ticket_Count', 'Family_Survival', 'Fare_PP_Log']\n",
                "cat_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'Sex_Pclass']\n",
                "\n",
                "preprocessor = ColumnTransformer([\n",
                "    ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), num_features),\n",
                "    ('cat', Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]), cat_features)\n",
                "])\n",
                "\n",
                "engineered_data = TitanicTrueMasterEngineer().transform(all_data)\n",
                "X_train = engineered_data[:891]\n",
                "y_train = pd.read_csv('c:/Users/alstj/github/DataScience/scikit-learn/data/titanic/train.csv')['Survived']\n",
                "X_test = engineered_data[891:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "69aa44b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# [The Final Elite Ensemble] \n",
                "rf = RandomForestClassifier(n_estimators=700, max_depth=6, min_samples_split=5, random_state=42)\n",
                "et = ExtraTreesClassifier(n_estimators=700, max_depth=6, random_state=42)\n",
                "xgb = XGBClassifier(n_estimators=700, learning_rate=0.01, max_depth=3, random_state=42, eval_metric='logloss')\n",
                "svc = SVC(C=1.0, kernel='rbf', probability=True, random_state=42)\n",
                "\n",
                "# ì„±ê²©ì´ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì„ ìµœì ì˜ ì¡°í™”ë¡œ ë¬¶ìŒ (RFì™€ SVCì˜ ë¹„ì¤‘ì„ ë†’ê²Œ ê· í˜• ì¡ìŒ)\n",
                "voting_clf = VotingClassifier(\n",
                "    estimators=[('rf', rf), ('et', et), ('xgb', xgb), ('svc', svc)],\n",
                "    voting='soft',\n",
                "    weights=[2, 1, 1, 2] # ê· í˜• ì¡íŒ ê°€ì¤‘ì¹˜\n",
                ")\n",
                "\n",
                "final_pipe = Pipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('classifier', voting_clf)\n",
                "])\n",
                "\n",
                "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
                "scores = cross_val_score(final_pipe, X_train, y_train, cv=cv)\n",
                "print(f\"The Last Chance CV Score: {scores.mean():.4f}\")\n",
                "\n",
                "final_pipe.fit(X_train, y_train)\n",
                "final_predictions = final_pipe.predict(X_test)\n",
                "\n",
                "submission = pd.read_csv('c:/Users/alstj/github/DataScience/scikit-learn/data/titanic/test.csv')[['PassengerId']]\n",
                "submission['Survived'] = final_predictions\n",
                "submission.to_csv('submission_the_last_chance.csv', index=False)\n",
                "print(\"ìµœì¢… ë§ˆì§€ë§‰ ê¸°íšŒ ì œì¶œ íŒŒì¼ 'submission_the_last_chance.csv' ì €ì¥ ì™„ë£Œ!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
