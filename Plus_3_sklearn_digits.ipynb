{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Scikit-learn 내장 데이터셋: load_digits 분석 및 분류 모델링\n",
                "\n",
                "이 노트북은 Scikit-learn에서 제공하는 손글씨 숫자(Digits) 데이터셋을 활용하여 데이터 분석(EDA), 전처리, 특성 엔지니어링, 그리고 6가지 머신러닝 모델을 통한 학습 및 앙상블 모델 구축 과정을 담고 있습니다.\n",
                "\n",
                "## 데이터셋 설명\n",
                "- **데이터셋 이름**: Optical Recognition of Handwritten Digits Data (손글씨 숫자 데이터)\n",
                "- **데이터 개수**: 1,797개\n",
                "- **특성(Features)**: 64개 (8x8 픽셀 이미지의 그레이스케일 값, 0~16 범위)\n",
                "- **타겟(Target)**: 0부터 9까지의 숫자 클래스\n",
                "- **주요 목표**: 8x8 픽셀 데이터를 입력받아 해당 숫자가 무엇인지 분류하는 다중 클래스 분류 문제 해결"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.datasets import load_digits\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "\n",
                "# 모델 라이브러리\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 데이터 로드 및 탐색적 데이터 분석 (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 데이터 로드\n",
                "digits = load_digits()\n",
                "X = digits.data\n",
                "y = digits.target\n",
                "\n",
                "print(f\"데이터셋 크기: {X.shape}\")\n",
                "print(f\"타겟 클래스: {np.unique(y)}\")\n",
                "\n",
                "# 데이터프레임 변환 (확인용)\n",
                "df = pd.DataFrame(X, columns=[f'pixel_{i}' for i in range(X.shape[1])])\n",
                "df['target'] = y\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1 데이터 시각화\n",
                "실제 8x8 이미지가 어떻게 생겼는지 확인해 봅니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 5))\n",
                "for index, (image, label) in enumerate(zip(digits.images[:10], digits.target[:10])):\n",
                "    plt.subplot(2, 5, index + 1)\n",
                "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
                "    plt.title(f'Target: {label}')\n",
                "    plt.axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2 클래스 분포 확인"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(8, 4))\n",
                "sns.countplot(x=y)\n",
                "plt.title(\"Distribution of Target Classes\")\n",
                "plt.xlabel(\"Digit\")\n",
                "plt.ylabel(\"Count\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 데이터 전처리 및 특성 엔지니어링"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 학습/테스트 데이터 분리\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 데이터 스케일링 (픽셀 값이 0~16으로 제한적이지만, 일부 모델의 수렴을 위해 표준화 수행)\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f\"X_train shape: {X_train.shape}\")\n",
                "print(f\"X_test shape: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 모델링 (6가지 모델 사용)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "models = {\n",
                "    \"LogisticRegression\": LogisticRegression(max_iter=10000),\n",
                "    \"SVC\": SVC(probability=True),\n",
                "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
                "    \"KNN\": KNeighborsClassifier(),\n",
                "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
                "    \"DecisionTree\": DecisionTreeClassifier(random_state=42)\n",
                "}\n",
                "\n",
                "results = {}\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train_scaled, y_train)\n",
                "    preds = model.predict(X_test_scaled)\n",
                "    acc = accuracy_score(y_test, preds)\n",
                "    results[name] = acc\n",
                "    print(f\"{name} Accuracy: {acc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 상위 4개 모델 선정 및 앙상블 모델 구축\n",
                "성능이 좋은 4가지 모델을 추려서 하이퍼 파라미터 튜닝을 진행하고 앙상블(Soft Voting) 모델을 만듭니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 성능 기준 내림차순 정렬\n",
                "sorted_models = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
                "top_4_names = [m[0] for m in sorted_models[:4]]\n",
                "print(f\"Top 4 Models: {top_4_names}\")\n",
                "\n",
                "# 간단한 튜닝 (GridSearchCV 예시 - 시간 관계상 일부 파라미터만 시연)\n",
                "tuned_models = []\n",
                "\n",
                "for name in top_4_names:\n",
                "    if name == 'SVC':\n",
                "        param_grid = {'C': [1, 10], 'gamma': ['scale', 0.01]}\n",
                "        grid = GridSearchCV(SVC(probability=True), param_grid, cv=3).fit(X_train_scaled, y_train)\n",
                "        tuned_models.append(('svc', grid.best_estimator_))\n",
                "    elif name == 'LogisticRegression':\n",
                "        param_grid = {'C': [0.1, 1.0, 10.0]}\n",
                "        grid = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=3).fit(X_train_scaled, y_train)\n",
                "        tuned_models.append(('logreg', grid.best_estimator_))\n",
                "    elif name == 'RandomForest':\n",
                "        param_grid = {'n_estimators': [100, 200], 'max_depth': [None, 10]}\n",
                "        grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3).fit(X_train_scaled, y_train)\n",
                "        tuned_models.append(('rf', grid.best_estimator_))\n",
                "    elif name == 'KNN':\n",
                "        param_grid = {'n_neighbors': [3, 5, 7]}\n",
                "        grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=3).fit(X_train_scaled, y_train)\n",
                "        tuned_models.append(('knn', grid.best_estimator_))\n",
                "    elif name == 'GradientBoosting':\n",
                "        param_grid = {'n_estimators': [50, 100], 'learning_rate': [0.1, 0.05]}\n",
                "        grid = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid, cv=3).fit(X_train_scaled, y_train)\n",
                "        tuned_models.append(('gb', grid.best_estimator_))\n",
                "    elif name == 'DecisionTree':\n",
                "        param_grid = {'max_depth': [None, 5, 10]}\n",
                "        grid = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=3).fit(X_train_scaled, y_train)\n",
                "        tuned_models.append(('dt', grid.best_estimator_))\n",
                "\n",
                "# 앙상블 생성\n",
                "voting_clf = VotingClassifier(estimators=tuned_models, voting='soft')\n",
                "voting_clf.fit(X_train_scaled, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 최종 평가"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = voting_clf.predict(X_test_scaled)\n",
                "print(\"Best 4 Ensemble Accuracy:\", accuracy_score(y_test, y_pred))\n",
                "print(\"\\n--- Classification Report ---\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "\n",
                "# Confusion Matrix 시각화\n",
                "plt.figure(figsize=(10, 8))\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.title(\"Confusion Matrix\")\n",
                "plt.xlabel(\"Predicted\")\n",
                "plt.ylabel(\"Actual\")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}